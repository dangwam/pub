{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf41f3f-591c-4ef4-9894-264422a45b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yfinance as yf\n",
    "from yahooquery import Ticker\n",
    "from yahooquery import Screener\n",
    "from datetime import datetime\n",
    "s = Screener()\n",
    "\n",
    "data_path = r'C:\\Users\\pythonProject\\data\\data_produced\\yquerry_screens\\options'\n",
    "folder_path = r\"C:\\Users\\pythonProject\\data\\data_produced\\yquerry_screens\"\n",
    "today = datetime.today().strftime('%Y%m%d')\n",
    "file_name = data_path + f\"\\\\{today}_option_data_multiple_tickers.csv\"\n",
    "scr_file_name = data_path + f\"\\\\{today}_option_screen_base_data.xlsx\"\n",
    "excel_file_path = os.path.join(data_path, scr_file_name) \n",
    "screen_option_data_file = data_path + f\"\\\\{today}_screen_option_data_file.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e83d4ea-298f-4562-b158-01d9fc288893",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = 'FSR'\n",
    "file_name_temp = data_path + f\"\\\\{today}_{stock}_option_data.csv\"\n",
    "t = Ticker(stock, asynchronous=True)\n",
    "df = t.option_chain\n",
    "df.to_csv(file_name_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6da9111-9aab-4fd9-aee5-10127a36e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Creating file ==> {today}_option_screen_base_data.xlsx\n",
    "\"\"\"\n",
    "This program reads the screen_list and generates the data for these screens using yahoo API.Then writes\n",
    "it to an excel file with tab for each screen.\n",
    "\n",
    "Additionally , all the data is also combined into a single dataframe combined_df for further use .\n",
    "\n",
    "\"\"\"\n",
    "screen_list = ['aggressive_small_caps', 'most_watched_tickers', 'most_actives', 'upside_breakout_stocks_daily',\n",
    "               'top_options_open_interest', 'most_shorted_stocks']\n",
    "\n",
    "dict_type = {'key1' : 'quotes', 'key2' : 'symbol'}\n",
    "\n",
    "columns = ['symbol','customPriceAlertConfidence','averageAnalystRating','regularMarketPrice','fiftyTwoWeekRange','sharesOutstanding','fiftyTwoWeekLow','fiftyTwoWeekHigh',\n",
    "           'regularMarketVolume',  'averageDailyVolume10Day', 'averageDailyVolume3Month', \n",
    "           'marketCap', 'bookValue', 'longName']\n",
    "\n",
    "columns_most_oi = ['symbol', 'optionsType', 'strike', 'expireDate', 'openInterest', 'regularMarketPrice', 'fiftyTwoWeekRange', 'regularMarketVolume',\n",
    "           'priceHint']\n",
    "\n",
    "# Function to convert Unix timestamp to formatted date\n",
    "def convert_unix_to_date(timestamp):\n",
    "    date_time = datetime.utcfromtimestamp(timestamp)\n",
    "    formatted_date = date_time.strftime('%Y-%m-%d')\n",
    "    return formatted_date\n",
    "\n",
    "def screen_tickers(scr, columns):\n",
    "    screen_data_dict = s.get_screeners([scr])\n",
    "    screen_data_list = screen_data_dict[scr]['quotes']\n",
    "    return pd.DataFrame(screen_data_list, columns = columns)\n",
    "\n",
    "with pd.ExcelWriter(excel_file_path, engine='xlsxwriter') as writer:\n",
    "    combined_df = None\n",
    "    for scr in screen_list: \n",
    "        screen_df = screen_tickers(scr, columns)\n",
    "        # Append subsequent DataFrames to the combined DataFrame (in-place)\n",
    "        if combined_df is None:\n",
    "            combined_df = screen_df  # First iteration: assign screen_df to combined_df\n",
    "        else:\n",
    "            combined_df = pd.concat([combined_df, screen_df], ignore_index=True)  # Append subsequent DataFrames\n",
    "        screen_df.to_excel(writer, sheet_name=scr, index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9165054c-6d4c-47ad-8151-892749cfc6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 120 stocks in this list\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 58385 entries, ('AAPL', Timestamp('2024-03-01 00:00:00'), 'calls') to ('XOM', Timestamp('2026-12-18 00:00:00'), 'puts')\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   contractSymbol     58385 non-null  object        \n",
      " 1   strike             58385 non-null  float64       \n",
      " 2   currency           58385 non-null  object        \n",
      " 3   lastPrice          58385 non-null  float64       \n",
      " 4   change             58385 non-null  float64       \n",
      " 5   percentChange      58385 non-null  float64       \n",
      " 6   volume             58385 non-null  float64       \n",
      " 7   openInterest       58385 non-null  float64       \n",
      " 8   bid                58385 non-null  float64       \n",
      " 9   ask                58385 non-null  float64       \n",
      " 10  contractSize       58385 non-null  object        \n",
      " 11  lastTradeDate      58385 non-null  datetime64[ns]\n",
      " 12  impliedVolatility  58385 non-null  float64       \n",
      " 13  inTheMoney         58385 non-null  bool          \n",
      "dtypes: bool(1), datetime64[ns](1), float64(9), object(3)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "this program creates a list of uniques symbols from the screen data extracted previously and then uses\n",
    "this new list to extraxt option data for each symbol.\n",
    "\n",
    "\"\"\"\n",
    "stocklist = combined_df['symbol'].drop_duplicates().tolist()\n",
    "print(f\"there are {len(stocklist)} stocks in this list\")\n",
    "\n",
    "def fetch_option_data(stocklist):\n",
    "    t = Ticker(stocklist, asynchronous=True)\n",
    "    most_option_df = t.option_chain\n",
    "    \n",
    "    return most_option_df.sort_values(by=\"symbol\")\n",
    "\n",
    "most_option_df = fetch_option_data(stocklist)\n",
    "most_option_df.to_csv(screen_option_data_file) \n",
    "most_option_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265171d5-4ded-40cd-9b8a-aeb558172f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['VIX240522C00060000']: Exception('%ticker%: No price data found, symbol may be delisted (period=1d)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error fetching price for VIX240522C00060000: single positional indexer is out-of-bounds\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['VIX240320C00047500']: Exception('%ticker%: No price data found, symbol may be delisted (period=1d)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error fetching price for VIX240320C00047500: single positional indexer is out-of-bounds\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['EEM250117C00040000']: Exception('%ticker%: No price data found, symbol may be delisted (period=1d)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error fetching price for EEM250117C00040000: single positional indexer is out-of-bounds\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "next , fetch latest prices for the stocks in the screen data list\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def fetch_latest_prices(tickers):\n",
    "    error_list = []\n",
    "    stock_data = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            data = yf.download(ticker, period=\"1d\", interval=\"1m\")\n",
    "            latest_price = data[\"Close\"].iloc[-1]\n",
    "            stock_data = pd.concat([stock_data, pd.DataFrame({\"Ticker\": ticker, \"Latest_Price\": latest_price}, index=[0])])\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching price for {ticker}: {e}\")\n",
    "            error_list.append(ticker)\n",
    "    \n",
    "    stock_data = stock_data.sort_values(by=\"Ticker\")\n",
    "    return stock_data, error_list\n",
    "\n",
    "# Example usage:\n",
    "#tickers = [\"AAPL\", \"GOOG\", \"MSFT\", \"INVALID\"]  # Replace with your list of tickers\n",
    "stock_data, error_list = fetch_latest_prices(stocklist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e440cbc-9def-4b25-ab2d-b4a304ff0fc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot join with no overlapping index names",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m  \u001b[38;5;66;03m# Import numpy for NaN handling\u001b[39;00m\n\u001b[0;32m     12\u001b[0m temp_file \u001b[38;5;241m=\u001b[39m data_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtemp_file.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 14\u001b[0m joined_df \u001b[38;5;241m=\u001b[39m \u001b[43mmost_option_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mouter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Apply the conditional logic using np.where\u001b[39;00m\n\u001b[0;32m     16\u001b[0m joined_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mriskPremium\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(joined_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minTheMoney\u001b[39m\u001b[38;5;124m\"\u001b[39m] ,\n\u001b[0;32m     17\u001b[0m                                     (joined_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrike\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m joined_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlastPrice\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m-\u001b[39m joined_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatest_Price\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     18\u001b[0m                                     joined_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlastPrice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\pandas\\core\\frame.py:10412\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[0;32m  10402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[0;32m  10404\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10405\u001b[0m             other,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10410\u001b[0m             validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m  10411\u001b[0m         )\n\u001b[1;32m> 10412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10413\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m  10418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m  10419\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10420\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m  10424\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:183\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    170\u001b[0m         left_df,\n\u001b[0;32m    171\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:883\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[1;32m--> 883\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    885\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    886\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    887\u001b[0m )\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1119\u001b[0m, in \u001b[0;36m_MergeOperation._get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1116\u001b[0m right_ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_index \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1119\u001b[0m     join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[43mleft_ax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_ax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_indexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_index \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1124\u001b[0m     join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m _left_join_on_index(\n\u001b[0;32m   1125\u001b[0m         left_ax, right_ax, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort\n\u001b[0;32m   1126\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:267\u001b[0m, in \u001b[0;36m_maybe_return_indexers.<locals>.join\u001b[1;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(meth)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m     sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    266\u001b[0m ):\n\u001b[1;32m--> 267\u001b[0m     join_index, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_indexers:\n\u001b[0;32m    269\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m join_index\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:4622\u001b[0m, in \u001b[0;36mIndex.join\u001b[1;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[0;32m   4620\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   4621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4622\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_join_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4624\u001b[0m \u001b[38;5;66;03m# join on the level\u001b[39;00m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi \u001b[38;5;129;01mor\u001b[39;00m other\u001b[38;5;241m.\u001b[39m_is_multi):\n",
      "File \u001b[1;32mC:\\Users\\pthon\\anaconda3\\envs\\ta_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:4745\u001b[0m, in \u001b[0;36mIndex._join_multi\u001b[1;34m(self, other, how)\u001b[0m\n\u001b[0;32m   4743\u001b[0m \u001b[38;5;66;03m# need at least 1 in common\u001b[39;00m\n\u001b[0;32m   4744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overlap:\n\u001b[1;32m-> 4745\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join with no overlapping index names\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, MultiIndex) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, MultiIndex):\n\u001b[0;32m   4748\u001b[0m     \u001b[38;5;66;03m# Drop the non-matching levels from left and right respectively\u001b[39;00m\n\u001b[0;32m   4749\u001b[0m     ldrop_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(self_names \u001b[38;5;241m-\u001b[39m overlap, key\u001b[38;5;241m=\u001b[39mself_names_order)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot join with no overlapping index names"
     ]
    }
   ],
   "source": [
    "## combined_df ,screen_df ,most_option_df, stock_data\n",
    "## print(combined_df.info())\n",
    "## print(screen_df.info())\n",
    "## print(most_option_df.info())\n",
    "##stock_data.set_index(\"Ticker\", inplace = True)\n",
    "\"\"\"\n",
    "This program calculates potential returns for all the options and then ranks based on the returs calculated. User\n",
    "sets a future price against which these returns are calculated to help make a descision on risk/reward\n",
    "\"\"\"\n",
    "import numpy as np  # Import numpy for NaN handling\n",
    "\n",
    "temp_file = data_path + f\"\\\\temp_file.csv\"\n",
    "\n",
    "joined_df = most_option_df.join(stock_data, how=\"outer\")\n",
    "# Apply the conditional logic using np.where\n",
    "joined_df[\"riskPremium\"] = np.where(joined_df[\"inTheMoney\"] ,\n",
    "                                    (joined_df[\"strike\"] + joined_df[\"lastPrice\"]) - joined_df[\"Latest_Price\"],\n",
    "                                    joined_df[\"lastPrice\"])\n",
    "\n",
    "joined_df.to_csv(temp_file)\n",
    "#calculate_future_stock_prices(joined_df, stocklist )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b0fb486b-93b3-4caf-ad1d-588ca1856f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Latest_Price\n",
      "Ticker                          \n",
      "AAPL                  195.470001\n",
      "ABR                    13.865000\n",
      "AG                      4.810100\n",
      "AHT                     1.475000\n",
      "AI                     26.150000\n",
      "...                          ...\n",
      "VIX240417C00060000      0.130000\n",
      "VZ                     41.955002\n",
      "WMT                   162.455002\n",
      "XLE240315P00080000      1.590000\n",
      "XOM                    99.095001\n",
      "\n",
      "[101 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(stock_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f3d5325-3ed6-48ab-bc4e-f618816727cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stocklist =['FSR','RIVN','TSLA','DIS','GM','HD','BABA','AAPL','APPS','PLTR',\n",
    "            'EXPR','MARA','GME','BB','RKT','HD','SCHW','NIO']\n",
    "#stocklist =['FSR']\n",
    "t = Ticker(stocklist, asynchronous=True)\n",
    "df = t.option_chain\n",
    "df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79edf065-7160-47d9-a678-7a577473fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol  expiration optionType  strike  lastPrice  volume  openInterest\n",
      "0   AAPL  2024-01-26      calls    60.0     131.40     2.0             0\n",
      "1   AAPL  2024-01-26      calls    90.0      93.45     0.0             0\n",
      "2   AAPL  2024-01-26      calls   100.0      87.92     7.0             7\n",
      "3   AAPL  2024-01-26      calls   110.0      73.75     0.0             1\n",
      "4   AAPL  2024-01-26      calls   125.0      65.51     2.0             3\n"
     ]
    }
   ],
   "source": [
    "def optionratio():\n",
    "    \n",
    "    df_cols = ['symbol', 'expiration', 'optionType', 'strike','lastPrice', 'volume','openInterest']\n",
    "    group_cols = ['symbol','strike', 'expiration','optionType']\n",
    "    agg_dict = {'openInterest' : 'sum', 'volume' : 'sum'}\n",
    "    oi_df = pd.read_csv(file_name)\n",
    "    oi_df = oi_df.filter(df_cols)\n",
    "    print(oi_df.head())\n",
    "    oi_df = oi_df.groupby(group_cols).agg(agg_dict)\n",
    "    oi_df = oi_df.unstack(level = 3)\n",
    "    oi_df.to_csv(file_name_oi)\n",
    "    return oi_df\n",
    "\n",
    "df_temp = optionratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627b9bf8-ed80-4f42-b272-78d9ffd6ff77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e759c-5cae-4275-aacf-6873a8777d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf02521-433f-47d5-b01e-34744cb7fda2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
